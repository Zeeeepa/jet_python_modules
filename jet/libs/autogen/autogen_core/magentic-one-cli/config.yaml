# config.yaml
#
# The contents of this file will be copied into the 'config.yaml' file of
# every expanded Task, just prior to running the scenario. This provides a
# good place to store model or other configurations important for the scenario.

###############################
# Open AI model configuration #
###############################
# model_config: &client
#   provider: autogen_ext.models.openai.OpenAIChatCompletionClient
#   config:
#     model: gpt-4o

###############################
# Ollama model configuration #
###############################
model_config: &client
  provider: jet.adapters.autogen.ollama_client.OllamaChatCompletionClient
  config:
    model: llama3.2
    base_url: http://localhost:11434/
    api_key: ollama
    timeout: 300.0
    options:
      seed: 42
      temperature: 0
      num_keep: 0
      num_predict: -1
    model_info:
      function_calling: true
      json_output: true
      vision: false
      family: llama
      structured_output: true

client: *client

##############################
# Ollama model configuration #
##############################
#model_config: &client
#    provider: autogen_ext.models.openai.OpenAIChatCompletionClient
#    config:
#      model: deepseek-r1:7b
#      base_url: http://localhost:11434/v1/
#      api_key: ollama
#      model_info:
#        function_calling: false
#        json_output: false
#        vision: false
#        family: r1
#

#######################
# Used by MagenticOne #
#######################
orchestrator_client: *client
coder_client: *client
web_surfer_client: *client
file_surfer_client: *client
