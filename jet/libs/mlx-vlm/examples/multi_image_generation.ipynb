{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Image Generation\n",
    "\n",
    "In this example, you will learn how to generate text from multiple images using the supported models: `Qwen2-VL`, `Pixtral` and `llava-interleaved`.\n",
    "\n",
    "Multi-image generation allows you to pass a list of images to the model and generate text conditioned on all the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jethroestrada/.pyenv/versions/3.12.9/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mlx_vlm import load, apply_chat_template, generate\n",
    "from mlx_vlm.utils import load_image\n",
    "from mlx_vlm.utils import process_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\"images/cats.jpg\", \"images/desktop_setup.png\"]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe what you see in the images.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qwen2-VL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 12 files: 100%|██████████| 12/12 [00:00<00:00, 14961.85it/s]\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    }
   ],
   "source": [
    "# Load model and processor\n",
    "qwen_vl_model, qwen_vl_processor = load(\"mlx-community/Qwen2.5-VL-7B-Instruct-4bit\")\n",
    "# qwen_vl_model, qwen_vl_processor = load(\"mlx-community/Qwen2.5-VL-3B-Instruct-3bit\")\n",
    "qwen_vl_config = qwen_vl_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = apply_chat_template(qwen_vl_processor, qwen_vl_config, messages, num_images=len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Files: ['images/cats.jpg', 'images/desktop_setup.png'] \n",
      "\n",
      "Prompt: <|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "<|vision_start|><|image_pad|><|vision_end|><|vision_start|><|image_pad|><|vision_end|>Describe what you see in the images.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qwen_vl_output = generate(\n",
    "    qwen_vl_model,\n",
    "    qwen_vl_processor,\n",
    "    prompt,\n",
    "    images,\n",
    "    max_tokens=1000,\n",
    "    temperature=0.7,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixtral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and processor\n",
    "pixtral_model, pixtral_processor = load(\"mlx-community/pixtral-12b-4bit\")\n",
    "pixtral_config = pixtral_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = apply_chat_template(pixtral_processor, pixtral_config, messages, num_images=len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixtral requires images to be resized to the same shape in multi-image generation\n",
    "resized_images = [process_image(load_image(image), (560, 560), None) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixtral_output = generate(\n",
    "    pixtral_model,\n",
    "    pixtral_processor,\n",
    "    prompt,\n",
    "    resized_images,\n",
    "    max_tokens=1000,\n",
    "    temperature=0.7,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llava-Interleaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and processor\n",
    "llava_model, llava_processor = load(\"mlx-community/llava-interleave-qwen-0.5b-bf16\")\n",
    "llava_config = llava_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = apply_chat_template(llava_processor, llava_config, messages, num_images=len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_output = generate(\n",
    "    llava_model,\n",
    "    llava_processor,\n",
    "    prompt,\n",
    "    images,\n",
    "    max_tokens=1000,\n",
    "    temperature=0.7,\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
