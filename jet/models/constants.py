from typing import Dict, List, Tuple, Optional, TypedDict, Union
from jet.models.base import scan_local_hf_models
from jet.transformers.formatters import format_json
from jet.utils.object import max_getattr
from jet.logger import logger
from transformers import AutoConfig
from jet.models.model_types import (
    EmbedModelKey,
    EmbedModelValue,
    LLMModelKey,
    LLMModelValue,
    ModelKey,
    ModelType,
    ModelValue,
    model_keys_list,
    model_values_list,
    model_types_list,
)


MODEL_KEYS_LIST: List[str] = model_keys_list
MODEL_VALUES_LIST: List[str] = model_values_list
MODEL_TYPES_LIST: List[str] = model_types_list


AVAILABLE_LLM_MODELS: Dict[LLMModelKey, LLMModelValue] = {
    "deepseek-r1": "deepseek-ai/DeepSeek-R1",
    "deepseek-r1-distill-qwen-1.5b": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "deepseek-r1-distill-qwen-14b-4bit": "mlx-community/DeepSeek-R1-Distill-Qwen-14B-4bit",
    "gemma-3-1b-it": "google/gemma-3-1b-it",
    "gemma-3-4b-it": "google/gemma-3-4b-it",
    "gemma-3-12b-it-qat-4bit": "mlx-community/gemma-3-12b-it-qat-4bit",
    "gemma-3-1b-it-qat-4bit": "mlx-community/gemma-3-1b-it-qat-4bit",
    "gemma-3-4b-it-qat-4bit": "mlx-community/gemma-3-4b-it-qat-4bit",
    "gpt2": "gpt2",
    "llama-3.1-8b": "meta-llama/Llama-3.1-8B",
    "llama-3.2-1b": "meta-llama/Llama-3.2-1B",
    "llama-3.2-3b": "meta-llama/Llama-3.2-3B",
    "dolphin3.0-llama3.1-8b-4bit": "mlx-community/Dolphin3.0-Llama3.1-8B-4bit",
    "llama-3.1-8b-instruct-4bit": "mlx-community/Llama-3.1-8B-Instruct-4bit",
    "llama-3.2-1b-instruct-4bit": "mlx-community/Llama-3.2-1B-Instruct-4bit",
    "llama-3.2-3b-instruct-4bit": "mlx-community/Llama-3.2-3B-Instruct-4bit",
    "mistral-7b-instruct-v0.3": "mistralai/Mistral-7B-Instruct-v0.3",
    "mistral-nemo-instruct-2407-4bit": "mlx-community/Mistral-Nemo-Instruct-2407-4bit",
    "qwen1.5-0.5b-chat-4bit": "mlx-community/Qwen1.5-0.5B-Chat-4bit",
    "qwen2.5-14b-instruct-4bit": "mlx-community/Qwen2.5-14B-Instruct-4bit",
    "qwen2.5-7b-instruct-4bit": "mlx-community/Qwen2.5-7B-Instruct-4bit",
    "qwen2.5-coder-14b-instruct-4bit": "mlx-community/Qwen2.5-Coder-14B-Instruct-4bit",
    "qwen3-0.6b-4bit": "mlx-community/Qwen3-0.6B-4bit",
    "qwen3-0.6b-4bit-dwq-053125": "mlx-community/Qwen3-0.6B-4bit-DWQ-053125",
    "qwen3-1.7b-3bit": "mlx-community/Qwen3-1.7B-3bit",
    "qwen3-1.7b-4bit-dwq-053125": "mlx-community/Qwen3-1.7B-4bit-DWQ-053125",
    "qwen3-4b-3bit": "mlx-community/Qwen3-4B-3bit",
    "qwen3-4b-4bit": "mlx-community/Qwen3-4B-4bit-DWQ",
    "qwen3-8b-4bit": "mlx-community/Qwen3-8B-4bit-DWQ",
    "dolphin3.0-llama3.2-3b-4bit": "mlx-community/dolphin3.0-llama3.2-3B-4Bit",
    "pythia-70m": "EleutherAI/pythia-70m",
}

AVAILABLE_EMBED_MODELS: Dict[EmbedModelKey, EmbedModelValue] = {
    "bge-large": "BAAI/bge-large-en-v1.5",
    "pythia-70m": "EleutherAI/pythia-70m",
    "qwen3-embedding-0.6b": "Qwen/Qwen3-Embedding-0.6B",
    "qwen3-reranker-0.6b": "Qwen/Qwen3-Reranker-0.6B",
    "snowflake-arctic-embed-m": "Snowflake/snowflake-arctic-embed-m",
    "snowflake-arctic-embed:137m": "Snowflake/snowflake-arctic-embed-m-long",
    "snowflake-arctic-embed-s": "Snowflake/snowflake-arctic-embed-s",
    "specter": "allenai/specter",
    "bert-base-cased": "bert-base-cased",
    "bert-base-multilingual-cased": "bert-base-multilingual-cased",
    "bert-base-uncased": "bert-base-uncased",
    "ms-marco-minilm-l-6-v2": "cross-encoder/ms-marco-MiniLM-L-6-v2",
    "deepseek-r1": "deepseek-ai/DeepSeek-R1",
    "deepseek-r1-distill-qwen-1.5b": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "distilbert-base-uncased": "distilbert-base-uncased",
    "gemma-3-1b-it": "google/gemma-3-1b-it",
    "gemma-3-4b-it": "google/gemma-3-4b-it",
    "gpt2": "gpt2",
    "granite-embedding:278m": "ibm-granite/granite-embedding-278m-multilingual",
    "granite-embedding": "ibm-granite/granite-embedding-30m-english",
    "e5-base-v2": "intfloat/e5-base-v2",
    "llama-3.1-8b": "meta-llama/Llama-3.1-8B",
    "llama-3.2-1b": "meta-llama/Llama-3.2-1B",
    "llama-3.2-3b": "meta-llama/Llama-3.2-3B",
    "deberta-v3-small": "microsoft/deberta-v3-small",
    "mistral-7b-instruct-v0.3": "mistralai/Mistral-7B-Instruct-v0.3",
    "mxbai-embed-large": "mixedbread-ai/mxbai-embed-large-v1",
    "deepseek-r1-distill-qwen-14b-4bit": "mlx-community/DeepSeek-R1-Distill-Qwen-14B-4bit",
    "dolphin3.0-llama3.1-8b-4bit": "mlx-community/Dolphin3.0-Llama3.1-8B-4bit",
    "llama-3.1-8b-instruct-4bit": "mlx-community/Llama-3.1-8B-Instruct-4bit",
    "llama-3.2-1b-instruct-4bit": "mlx-community/Llama-3.2-1B-Instruct-4bit",
    "llama-3.2-3b-instruct-4bit": "mlx-community/Llama-3.2-3B-Instruct-4bit",
    "mistral-nemo-instruct-2407-4bit": "mlx-community/Mistral-Nemo-Instruct-2407-4bit",
    "qwen1.5-0.5b-chat-4bit": "mlx-community/Qwen1.5-0.5B-Chat-4bit",
    "qwen2.5-14b-instruct-4bit": "mlx-community/Qwen2.5-14B-Instruct-4bit",
    "qwen2.5-7b-instruct-4bit": "mlx-community/Qwen2.5-7B-Instruct-4bit",
    "qwen2.5-coder-14b-instruct-4bit": "mlx-community/Qwen2.5-Coder-14B-Instruct-4bit",
    "qwen3-0.6b-4bit": "mlx-community/Qwen3-0.6B-4bit",
    "qwen3-0.6b-4bit-dwq-053125": "mlx-community/Qwen3-0.6B-4bit-DWQ-053125",
    "qwen3-1.7b-3bit": "mlx-community/Qwen3-1.7B-3bit",
    "qwen3-1.7b-4bit-dwq-053125": "mlx-community/Qwen3-1.7B-4bit-DWQ-053125",
    "qwen3-4b-3bit": "mlx-community/Qwen3-4B-3bit",
    "qwen3-4b-4bit": "mlx-community/Qwen3-4B-4bit-DWQ",
    "qwen3-8b-4bit": "mlx-community/Qwen3-8B-4bit-DWQ",
    "qwen3-embedding-0.6b-4bit": "mlx-community/Qwen3-Embedding-0.6B-4bit-DWQ",
    "qwen3-embedding-4b-4bit-dwq": "mlx-community/Qwen3-Embedding-4B-4bit-DWQ",
    "all-minilm-l6-v2-4bit": "mlx-community/all-MiniLM-L6-v2-4bit",
    "all-minilm-l6-v2-6bit": "mlx-community/all-MiniLM-L6-v2-6bit",
    "all-minilm-l6-v2-8bit": "mlx-community/all-MiniLM-L6-v2-8bit",
    "all-minilm-l6-v2-bf16": "mlx-community/all-MiniLM-L6-v2-bf16",
    "dolphin3.0-llama3.2-3b-4bit": "mlx-community/dolphin3.0-llama3.2-3B-4Bit",
    "gemma-3-12b-it-qat-4bit": "mlx-community/gemma-3-12b-it-qat-4bit",
    "gemma-3-1b-it-qat-4bit": "mlx-community/gemma-3-1b-it-qat-4bit",
    "gemma-3-4b-it-qat-4bit": "mlx-community/gemma-3-4b-it-qat-4bit",
    "nomic-bert-2048": "nomic-ai/nomic-bert-2048",
    "nomic-embed-text": "nomic-ai/nomic-embed-text-v1.5",
    "roberta-base": "roberta-base",
    "roberta-large": "roberta-large",
    "all-MiniLM-L6-v2": "sentence-transformers/all-MiniLM-L6-v2",
    "all-mpnet-base-v2": "sentence-transformers/all-mpnet-base-v2",
    "allenai-specter": "sentence-transformers/allenai-specter",
    "distilbert-base-nli-stsb-mean-tokens": "sentence-transformers/distilbert-base-nli-stsb-mean-tokens",
    "paraphrase-multilingual": "sentence-transformers/paraphrase-MiniLM-L12-v2",
    "static-retrieval-mrl-en-v1": "sentence-transformers/static-retrieval-mrl-en-v1"
}


AVAILABLE_MODELS: Dict[ModelKey, ModelValue] = {
    **AVAILABLE_LLM_MODELS,
    **AVAILABLE_EMBED_MODELS,
}


ALL_MODELS: Dict[ModelKey, ModelValue] = {
    **AVAILABLE_LLM_MODELS,
    **AVAILABLE_EMBED_MODELS,
}
ALL_MODELS_REVERSED: Dict[ModelValue, ModelKey] = {
    v: k for k, v in ALL_MODELS.items()}
ALL_MODEL_KEYS: List[ModelKey] = list(ALL_MODELS.keys())
ALL_MODEL_VALUES: List[ModelValue] = list(ALL_MODELS.values())

MODEL_CONTEXTS: Dict[ModelType, int] = {
    "bge-large": 512,
    "pythia-70m": 2048,
    "qwen3-embedding-0.6b": 32768,
    "qwen3-reranker-0.6b": 40960,
    "snowflake-arctic-embed-m": 512,
    "snowflake-arctic-embed:137m": 8192,
    "snowflake-arctic-embed-s": 512,
    "specter": 512,
    "bert-base-cased": 512,
    "bert-base-multilingual-cased": 512,
    "bert-base-uncased": 512,
    "ms-marco-minilm-l-6-v2": 512,
    "deepseek-r1": 163840,
    "deepseek-r1-distill-qwen-1.5b": 131072,
    "distilbert-base-uncased": 512,
    "gemma-3-1b-it": 32768,
    "gemma-3-4b-it": 131072,
    "gpt2": 1024,
    "granite-embedding:278m": 514,
    "granite-embedding": 514,
    "e5-base-v2": 512,
    "llama-3.1-8b": 131072,
    "llama-3.2-1b": 131072,
    "llama-3.2-3b": 131072,
    "deberta-v3-small": 512,
    "mistral-7b-instruct-v0.3": 32768,
    "mxbai-embed-large": 512,
    "deepseek-r1-distill-qwen-14b-4bit": 131072,
    "dolphin3.0-llama3.1-8b-4bit": 131072,
    "llama-3.1-8b-instruct-4bit": 131072,
    "llama-3.2-1b-instruct-4bit": 131072,
    "llama-3.2-3b-instruct-4bit": 131072,
    "mistral-nemo-instruct-2407-4bit": 1024000,
    "qwen1.5-0.5b-chat-4bit": 32768,
    "qwen2.5-14b-instruct-4bit": 32768,
    "qwen2.5-7b-instruct-4bit": 32768,
    "qwen2.5-coder-14b-instruct-4bit": 32768,
    "qwen3-0.6b-4bit": 40960,
    "qwen3-0.6b-4bit-dwq-053125": 40960,
    "qwen3-1.7b-3bit": 40960,
    "qwen3-1.7b-4bit-dwq-053125": 40960,
    "qwen3-4b-3bit": 40960,
    "qwen3-4b-4bit": 40960,
    "qwen3-8b-4bit": 40960,
    "qwen3-embedding-0.6b-4bit": 32768,
    "qwen3-embedding-4b-4bit-dwq": 40960,
    "all-minilm-l6-v2-4bit": 512,
    "all-minilm-l6-v2-6bit": 512,
    "all-minilm-l6-v2-8bit": 512,
    "all-minilm-l6-v2-bf16": 512,
    "dolphin3.0-llama3.2-3b-4bit": 131072,
    "gemma-3-12b-it-qat-4bit": 131072,
    "gemma-3-1b-it-qat-4bit": 32768,
    "gemma-3-4b-it-qat-4bit": 131072,
    "nomic-bert-2048": 2048,
    "nomic-embed-text": 8192,
    "roberta-base": 514,
    "roberta-large": 514,
    "all-MiniLM-L6-v2": 512,
    "all-mpnet-base-v2": 514,
    "allenai-specter": 512,
    "distilbert-base-nli-stsb-mean-tokens": 512,
    "paraphrase-multilingual": 512
}

MODEL_EMBEDDING_TOKENS: Dict[ModelType, int] = {
    "bge-large": 1024,
    "pythia-70m": 512,
    "qwen3-embedding-0.6b": 1024,
    "qwen3-reranker-0.6b": 1024,
    "snowflake-arctic-embed-m": 768,
    "snowflake-arctic-embed:137m": 768,
    "snowflake-arctic-embed-s": 384,
    "specter": 768,
    "bert-base-cased": 768,
    "bert-base-multilingual-cased": 768,
    "bert-base-uncased": 768,
    "ms-marco-minilm-l-6-v2": 384,
    "deepseek-r1": 7168,
    "deepseek-r1-distill-qwen-1.5b": 1536,
    "distilbert-base-uncased": 768,
    "gemma-3-1b-it": 1152,
    "gemma-3-4b-it": 2560,
    "gpt2": 768,
    "granite-embedding:278m": 768,
    "granite-embedding": 384,
    "e5-base-v2": 768,
    "llama-3.1-8b": 4096,
    "llama-3.2-1b": 2048,
    "llama-3.2-3b": 3072,
    "deberta-v3-small": 768,
    "mistral-7b-instruct-v0.3": 4096,
    "mxbai-embed-large": 1024,
    "deepseek-r1-distill-qwen-14b-4bit": 5120,
    "dolphin3.0-llama3.1-8b-4bit": 4096,
    "llama-3.1-8b-instruct-4bit": 4096,
    "llama-3.2-1b-instruct-4bit": 2048,
    "llama-3.2-3b-instruct-4bit": 3072,
    "mistral-nemo-instruct-2407-4bit": 5120,
    "qwen1.5-0.5b-chat-4bit": 1024,
    "qwen2.5-14b-instruct-4bit": 5120,
    "qwen2.5-7b-instruct-4bit": 3584,
    "qwen2.5-coder-14b-instruct-4bit": 5120,
    "qwen3-0.6b-4bit": 1024,
    "qwen3-0.6b-4bit-dwq-053125": 1024,
    "qwen3-1.7b-3bit": 2048,
    "qwen3-1.7b-4bit-dwq-053125": 2048,
    "qwen3-4b-3bit": 2560,
    "qwen3-4b-4bit": 2560,
    "qwen3-8b-4bit": 4096,
    "qwen3-embedding-0.6b-4bit": 1024,
    "qwen3-embedding-4b-4bit-dwq": 2560,
    "all-minilm-l6-v2-4bit": 384,
    "all-minilm-l6-v2-6bit": 384,
    "all-minilm-l6-v2-8bit": 384,
    "all-minilm-l6-v2-bf16": 384,
    "dolphin3.0-llama3.2-3b-4bit": 3072,
    "gemma-3-12b-it-qat-4bit": 3840,
    "gemma-3-1b-it-qat-4bit": 1152,
    "gemma-3-4b-it-qat-4bit": 2560,
    "nomic-bert-2048": 768,
    "nomic-embed-text": 768,
    "roberta-base": 768,
    "roberta-large": 1024,
    "all-MiniLM-L6-v2": 384,
    "all-mpnet-base-v2": 768,
    "allenai-specter": 768,
    "distilbert-base-nli-stsb-mean-tokens": 768,
    "paraphrase-multilingual": 384,
    "static-retrieval-mrl-en-v1": 1024
}
